{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example_librispeech_training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OHy3V7O_lu-d",
        "Ld5EZj6_mnH5",
        "Zx-hzi6-o0ze"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vectominist/MiniASR/blob/main/example/example_librispeech_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc6s2gOOlg-W"
      },
      "source": [
        "# **MiniASR Tutorial: LibriSpeech Training**\n",
        "This is a tutorial for training an end-to-end automatic speech recognition model with the toolkit [MiniASR](https://github.com/vectominist/MiniASR).  \n",
        "You can run this notebook on [Google Colab](colab.research.google.com/), but to train an ASR model completely requires a Pro account since it needs several hours to converge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHy3V7O_lu-d"
      },
      "source": [
        "## **Download Code & Install Dependencies**\n",
        "Ref: [MiniASR](https://github.com/vectominist/MiniASR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3ZxMQbvk25k"
      },
      "source": [
        "! git clone https://github.com/vectominist/MiniASR.git\n",
        "% cd MiniASR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf7QLclNieZx"
      },
      "source": [
        "! pip3 install -e ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld5EZj6_mnH5"
      },
      "source": [
        "## **Download Data**\n",
        "- training set: [Libri-light](https://github.com/facebookresearch/libri-light) fine-tuning set (10 hours, 0.6G)\n",
        "- development set: [LibriSpeech](https://www.openslr.org/12) `dev-clean` set\n",
        "- testing set: [LibriSpeech](https://www.openslr.org/12) `test-clean` set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nmh3oywnAgZ"
      },
      "source": [
        "! mkdir -p data\n",
        "% cd data\n",
        "! wget https://dl.fbaipublicfiles.com/librilight/data/librispeech_finetuning.tgz\n",
        "! tar zxf librispeech_finetuning.tgz\n",
        "! rm librispeech_finetuning.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6BIVK1knUTK"
      },
      "source": [
        "! wget https://www.openslr.org/resources/12/dev-clean.tar.gz\n",
        "! wget https://www.openslr.org/resources/12/test-clean.tar.gz\n",
        "! tar zxf dev-clean.tar.gz\n",
        "! tar zxf test-clean.tar.gz\n",
        "! rm dev-clean.tar.gz\n",
        "! rm test-clean.tar.gz\n",
        "% cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx-hzi6-o0ze"
      },
      "source": [
        "## **Preprocess Data**\n",
        "Find all data in the corpus and extract vocabularies. We use characters as text tokens since the dataset is small."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWWcTzXho4b3"
      },
      "source": [
        "# Train set\n",
        "! miniasr-preprocess \\\n",
        "        -c LibriSpeech \\\n",
        "        -p data/librispeech_finetuning \\\n",
        "        -s 1h \\\n",
        "        -o data/libri_train_1h \\\n",
        "        --gen-vocab \\\n",
        "        --char-vocab-size 40\n",
        "\n",
        "! miniasr-preprocess \\\n",
        "        -c LibriSpeech \\\n",
        "        -p data/librispeech_finetuning \\\n",
        "        -s 9h \\\n",
        "        -o data/libri_train_9h\n",
        "\n",
        "# Development set\n",
        "! miniasr-preprocess \\\n",
        "        -c LibriSpeech \\\n",
        "        -p data/LibriSpeech \\\n",
        "        -s dev-clean \\\n",
        "        -o data/libri_dev\n",
        "\n",
        "# Test set\n",
        "! miniasr-preprocess \\\n",
        "        -c LibriSpeech \\\n",
        "        -p data/LibriSpeech \\\n",
        "        -s test-clean \\\n",
        "        -o data/libri_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcyY1IWMrezU"
      },
      "source": [
        "## **Training**\n",
        "- Modify `MiniASR/egs/librispeech/config/ctc_train_example.yaml` for changing training hyper-parameters.\n",
        "- The results will be saved to `MiniASR/model/ctc_libri-10h_char`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDENJR7Wq7pN"
      },
      "source": [
        "! mkdir -p model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTBUATPSsXsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09ddbd8-d41d-459f-f769-739aacfe09de"
      },
      "source": [
        "! minasr-asr --config egs/librispeech/config/ctc_train_example.yaml\n",
        "\n",
        "# Resume training with this command:\n",
        "# ! minasr-asr --ckpt model/ctc_libri-10h_char/epoch=4-step=429.ckpt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10-01 12:12 run_asr.py.main(99) Training mode.\n",
            "10-01 12:12 dataloader.py.create_dataloader(86) Creating text tokenizer of character level.\n",
            "10-01 12:12 dataloader.py.create_dataloader(91) Generating datasets and dataloaders. (mode = train)\n",
            "10-01 12:12 dataset.py.__init__(28) Loading data from ['data/libri_train_1h/data_list_sorted.json', 'data/libri_train_9h/data_list_sorted.json']\n",
            "100% 2763/2763 [00:00<00:00, 12494.93it/s]\n",
            "10-01 12:12 dataset.py.__init__(49) 2763 audio files found (mode = train)\n",
            "10-01 12:12 dataset.py.__init__(28) Loading data from ['data/libri_dev/data_list_sorted.json']\n",
            "100% 2703/2703 [00:00<00:00, 21381.83it/s]\n",
            "10-01 12:12 dataset.py.__init__(49) 2703 audio files found (mode = dev)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "10-01 12:12 asr_trainer.py.create_asr_trainer(24) Creating ASR model (type = ctc_asr).\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.wav2vec.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.wav2vec2_hug.expert: No module named 'transformers'. Pass.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.roberta.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.vq_wav2vec.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.wav2vec2.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.hubert.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.decoar2.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.wav2vec.hubconf: No module named 'fairseq'. Please see upstream/wav2vec/README.md\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.wav2vec2_hug.hubconf: No module named 'transformers'. Please see upstream/wav2vec2_hug/README.md\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.roberta.hubconf: No module named 'fairseq'. Please see upstream/roberta/README.md\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.vq_wav2vec.hubconf: No module named 'fairseq'. Please see upstream/vq_wav2vec/README.md\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.wav2vec2.hubconf: No module named 'fairseq'. Please see upstream/wav2vec2/README.md\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.hubert.hubconf: No module named 'fairseq'. Please see upstream/hubert/README.md\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.decoar2.hubconf: No module named 'fairseq'. Please see upstream/decoar2/README.md\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.enhancement_stft.expert: No module named 'asteroid'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.quesst14_dtw.expert: No module named 'dtw'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.speech_translation.expert: No module named 'sacrebleu'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.asr.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.voxceleb2_ge2e.expert: No module named 'sox'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.sv_voxceleb1.expert: No module named 'sox'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.separation_stft.expert: No module named 'asteroid'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.speech_commands.expert: No module named 'catalyst'. Pass.\n",
            "Using native 16bit precision.\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name             | Type             | Params\n",
            "------------------------------------------------------\n",
            "0 | extractor        | UpstreamExpert   | 0     \n",
            "1 | feat_select      | FeatureSelection | 0     \n",
            "2 | encoder          | RNNEncoder       | 3.1 M \n",
            "3 | ctc_output_layer | Linear           | 15.9 K\n",
            "4 | ctc_loss         | CTCLoss          | 0     \n",
            "------------------------------------------------------\n",
            "3.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.1 M     Total params\n",
            "12.585    Total estimated model params size (MB)\n",
            "Validation sanity check:   0% 0/2 [00:00<?, ?it/s]\n",
            "10-01 12:12 base_asr.py.validation_epoch_end(219) Val CER = 92.9% , WER = 100.0% , Loss = 18.55\n",
            "Epoch 4:  58% 100/171 [01:25<01:00,  1.18it/s, loss=2.79, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  70% 120/171 [01:36<00:40,  1.25it/s, loss=2.79, v_num=0]\n",
            "Epoch 4:  82% 140/171 [01:42<00:22,  1.38it/s, loss=2.79, v_num=0]\n",
            "Epoch 4:  94% 160/171 [01:47<00:07,  1.50it/s, loss=2.79, v_num=0]\n",
            "Validating:  94% 80/85 [00:24<00:01,  3.75it/s]\u001b[A\n",
            "Validating: 100% 85/85 [00:25<00:00,  4.04it/s]\u001b[A\n",
            "10-01 12:20 base_asr.py.validation_epoch_end(219) Val CER = 84.4% , WER = 104.3% , Loss = 2.80\n",
            "Epoch 4: 100% 171/171 [02:03<00:00,  1.39it/s, loss=2.78, v_num=0]\n",
            "Epoch 9:  58% 100/171 [01:25<01:00,  1.18it/s, loss=2.29, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  70% 120/171 [01:36<00:40,  1.25it/s, loss=2.29, v_num=0]\n",
            "Epoch 9:  82% 140/171 [01:42<00:22,  1.37it/s, loss=2.29, v_num=0]\n",
            "Epoch 9:  94% 160/171 [01:47<00:07,  1.50it/s, loss=2.29, v_num=0]\n",
            "Validating:  94% 80/85 [00:25<00:01,  3.76it/s]\u001b[A\n",
            "Epoch 9: 100% 171/171 [01:58<00:00,  1.45it/s, loss=2.29, v_num=0]\n",
            "10-01 12:28 base_asr.py.validation_epoch_end(219) Val CER = 70.5% , WER = 111.0% , Loss = 2.22\n",
            "Epoch 9: 100% 171/171 [02:18<00:00,  1.24it/s, loss=2.29, v_num=0]\n",
            "Epoch 14:  58% 100/171 [01:25<01:00,  1.18it/s, loss=1.98, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14:  70% 120/171 [01:36<00:40,  1.25it/s, loss=1.98, v_num=0]\n",
            "Epoch 14:  82% 140/171 [01:42<00:22,  1.38it/s, loss=1.98, v_num=0]\n",
            "Epoch 14:  94% 160/171 [01:46<00:07,  1.51it/s, loss=1.98, v_num=0]\n",
            "Validating:  94% 80/85 [00:24<00:01,  3.79it/s]\u001b[A\n",
            "Epoch 14: 100% 171/171 [02:06<00:00,  1.36it/s, loss=1.98, v_num=0]\n",
            "10-01 12:36 base_asr.py.validation_epoch_end(219) Val CER = 57.3% , WER = 102.2% , Loss = 1.89\n",
            "Epoch 14: 100% 171/171 [02:31<00:00,  1.13it/s, loss=2, v_num=0]   \n",
            "Epoch 19:  58% 100/171 [01:26<01:00,  1.17it/s, loss=1.78, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 19:  70% 120/171 [01:37<00:40,  1.25it/s, loss=1.78, v_num=0]\n",
            "Epoch 19:  82% 140/171 [01:43<00:22,  1.37it/s, loss=1.78, v_num=0]\n",
            "Epoch 19:  94% 160/171 [01:47<00:07,  1.49it/s, loss=1.78, v_num=0]\n",
            "Validating:  94% 80/85 [00:25<00:01,  3.76it/s]\u001b[A\n",
            "Epoch 19: 100% 171/171 [02:01<00:00,  1.42it/s, loss=1.78, v_num=0]\n",
            "10-01 12:45 base_asr.py.validation_epoch_end(219) Val CER = 53.0% , WER = 96.2% , Loss = 1.70\n",
            "Epoch 19: 100% 171/171 [02:33<00:00,  1.12it/s, loss=1.78, v_num=0]\n",
            "Epoch 24:  58% 100/171 [01:25<01:00,  1.18it/s, loss=1.63, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 24:  70% 120/171 [01:36<00:40,  1.25it/s, loss=1.63, v_num=0]\n",
            "Epoch 24:  82% 140/171 [01:42<00:22,  1.37it/s, loss=1.63, v_num=0]\n",
            "Epoch 24:  94% 160/171 [01:47<00:07,  1.50it/s, loss=1.63, v_num=0]\n",
            "Validating:  94% 80/85 [00:25<00:01,  3.75it/s]\u001b[A\n",
            "Epoch 24: 100% 171/171 [02:03<00:00,  1.39it/s, loss=1.63, v_num=0]\n",
            "10-01 12:53 base_asr.py.validation_epoch_end(219) Val CER = 48.5% , WER = 98.7% , Loss = 1.56\n",
            "Epoch 24: 100% 171/171 [02:37<00:00,  1.09it/s, loss=1.63, v_num=0]\n",
            "Epoch 29:  58% 100/171 [01:26<01:00,  1.17it/s, loss=1.51, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 29:  70% 120/171 [01:37<00:40,  1.25it/s, loss=1.51, v_num=0]\n",
            "Epoch 29:  82% 140/171 [01:42<00:22,  1.37it/s, loss=1.51, v_num=0]\n",
            "Epoch 29:  94% 160/171 [01:47<00:07,  1.50it/s, loss=1.51, v_num=0]\n",
            "Validating:  94% 80/85 [00:25<00:01,  3.77it/s]\u001b[A\n",
            "Epoch 29: 100% 171/171 [02:01<00:00,  1.41it/s, loss=1.51, v_num=0]\n",
            "10-01 13:02 base_asr.py.validation_epoch_end(219) Val CER = 45.9% , WER = 94.4% , Loss = 1.47\n",
            "Epoch 29: 100% 171/171 [02:39<00:00,  1.08it/s, loss=1.53, v_num=0]\n",
            "Epoch 34:  58% 100/171 [01:26<01:00,  1.17it/s, loss=1.42, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 34:  70% 120/171 [01:37<00:40,  1.25it/s, loss=1.42, v_num=0]\n",
            "Epoch 34:  82% 140/171 [01:43<00:22,  1.37it/s, loss=1.42, v_num=0]\n",
            "Epoch 34:  94% 160/171 [01:47<00:07,  1.50it/s, loss=1.42, v_num=0]\n",
            "Validating:  94% 80/85 [00:24<00:01,  3.79it/s]\u001b[A\n",
            "Epoch 34: 100% 171/171 [01:57<00:00,  1.46it/s, loss=1.42, v_num=0]\n",
            "10-01 13:10 base_asr.py.validation_epoch_end(219) Val CER = 43.2% , WER = 90.8% , Loss = 1.38\n",
            "Epoch 34: 100% 171/171 [02:39<00:00,  1.08it/s, loss=1.41, v_num=0]\n",
            "Epoch 39:  58% 100/171 [01:25<01:00,  1.18it/s, loss=1.35, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 39:  58% 100/171 [01:35<01:07,  1.06it/s, loss=1.35, v_num=0]\n",
            "Epoch 39:  70% 120/171 [01:36<00:40,  1.25it/s, loss=1.35, v_num=0]\n",
            "Epoch 39:  82% 140/171 [01:42<00:22,  1.37it/s, loss=1.35, v_num=0]\n",
            "Epoch 39:  94% 160/171 [01:47<00:07,  1.50it/s, loss=1.35, v_num=0]\n",
            "Validating:  94% 80/85 [00:25<00:01,  3.76it/s]\u001b[A\n",
            "Epoch 39: 100% 171/171 [02:05<00:00,  1.37it/s, loss=1.35, v_num=0]\n",
            "10-01 13:18 base_asr.py.validation_epoch_end(219) Val CER = 41.0% , WER = 89.7% , Loss = 1.34\n",
            "Epoch 39: 100% 171/171 [02:42<00:00,  1.06it/s, loss=1.35, v_num=0]\n",
            "Epoch 44:  58% 100/171 [01:25<00:59,  1.18it/s, loss=1.26, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/85 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 44:  70% 120/171 [01:36<00:40,  1.26it/s, loss=1.26, v_num=0]\n",
            "Epoch 44:  82% 140/171 [01:42<00:22,  1.38it/s, loss=1.26, v_num=0]\n",
            "Epoch 44:  94% 160/171 [01:46<00:07,  1.51it/s, loss=1.26, v_num=0]\n",
            "Validating:  94% 80/85 [00:24<00:01,  3.78it/s]\u001b[A\n",
            "Epoch 44: 100% 171/171 [02:01<00:00,  1.41it/s, loss=1.26, v_num=0]\n",
            "10-01 13:27 base_asr.py.validation_epoch_end(219) Val CER = 39.7% , WER = 86.5% , Loss = 1.28\n",
            "Epoch 44: 100% 171/171 [02:40<00:00,  1.07it/s, loss=1.28, v_num=0]\n",
            "Epoch 45:  47% 40/86 [00:54<01:01,  1.34s/it, loss=1.29, v_num=0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVXy9YUVuLpt"
      },
      "source": [
        "## **Testing**\n",
        "- Specify your checkpoint with `--ckpt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3B1mCCKuOYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe244d16-6eeb-469a-b663-80afd04f3e01"
      },
      "source": [
        "! minasr-asr \\\n",
        "    --config egs/librispeech/config/ctc_test_example.yaml \\\n",
        "    --test \\\n",
        "    --override \"args.data.dev_paths=['data/libri_test/data_list_sorted.json']\" \\\n",
        "    --ckpt model/ctc_libri-10h_char/epoch=44-step=3869.ckpt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10-01 13:28 basic_setups.py.override(89) Override: args.data.dev_paths = ['data/libri_test/data_list_sorted.json']\n",
            "10-01 13:28 run_asr.py.main(105) Testing mode.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.wav2vec.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.wav2vec2_hug.expert: No module named 'transformers'. Pass.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.roberta.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.vq_wav2vec.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.wav2vec2.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.hubert.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.upstream.experts] Warning: can not import s3prl.upstream.decoar2.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.wav2vec.hubconf: No module named 'fairseq'. Please see upstream/wav2vec/README.md\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.wav2vec2_hug.hubconf: No module named 'transformers'. Please see upstream/wav2vec2_hug/README.md\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.roberta.hubconf: No module named 'fairseq'. Please see upstream/roberta/README.md\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.vq_wav2vec.hubconf: No module named 'fairseq'. Please see upstream/vq_wav2vec/README.md\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.wav2vec2.hubconf: No module named 'fairseq'. Please see upstream/wav2vec2/README.md\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.hubert.hubconf: No module named 'fairseq'. Please see upstream/hubert/README.md\n",
            "[s3prl.hub] Warning: can not import s3prl.upstream.decoar2.hubconf: No module named 'fairseq'. Please see upstream/decoar2/README.md\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.enhancement_stft.expert: No module named 'asteroid'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.quesst14_dtw.expert: No module named 'dtw'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.speech_translation.expert: No module named 'sacrebleu'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.asr.expert: No module named 'fairseq'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.voxceleb2_ge2e.expert: No module named 'sox'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.sv_voxceleb1.expert: No module named 'sox'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.separation_stft.expert: No module named 'asteroid'. Pass.\n",
            "[s3prl.downstream.experts] Warning: can not import s3prl.downstream.speech_commands.expert: No module named 'catalyst'. Pass.\n",
            "10-01 13:28 dataloader.py.create_dataloader(91) Generating datasets and dataloaders. (mode = dev)\n",
            "10-01 13:28 dataset.py.__init__(28) Loading data from ['data/libri_test/data_list_sorted.json']\n",
            "100% 2620/2620 [00:00<00:00, 21892.29it/s]\n",
            "10-01 13:28 dataset.py.__init__(49) 2620 audio files found (mode = dev)\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 100% 164/164 [00:39<00:00,  8.80it/s]\n",
            "\n",
            "Character errors\n",
            "| #Snt     #Tok     | Sub    Del    Ins    Err    SErr   |\n",
            "| 2620     281530   | 16.7   21.1   1.5    39.2   100.0  |\n",
            "\n",
            "Word errors\n",
            "| #Snt     #Tok     | Sub    Del    Ins    Err    SErr   |\n",
            "| 2620     52576    | 74.7   7.2    4.4    86.4   100.0  |\n",
            "\n",
            "RTF:     0.0013\n",
            "Latency: 9.3666 [ms/sentence]\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{}\n",
            "--------------------------------------------------------------------------------\n",
            "Testing: 100% 164/164 [01:19<00:00,  2.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTjPqeq-EIh8"
      },
      "source": [
        "## **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99pGiNgrRNSZ"
      },
      "source": [
        "from miniasr.utils import load_from_checkpoint, sequence_distance\n",
        "from miniasr.data.audio import load_waveform\n",
        "\n",
        "model, args, tokenizer = load_from_checkpoint(\n",
        "    'model/ctc_libri-10h_char/epoch=44-step=3869.ckpt', 'cuda')\n",
        "waves = [load_waveform('data/LibriSpeech/dev-clean/6345/93302/6345-93302-0025.flac').to('cuda')]\n",
        "hyps = model.recognize(waves)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UazYyxmZSKOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b56a5cc-6e36-41a6-a730-75eeb0558717"
      },
      "source": [
        "print(hyps[0])\n",
        "ref = 'ARE YOU REALLY GOING TO THROW ME OVER FOR A THING LIKE THIS'\n",
        "res_cer = sequence_distance(ref, hyps[0], mode='char')\n",
        "res_wer = sequence_distance(ref, hyps[0], mode='word')\n",
        "print('CER = {:.2f}%'.format(100. * res_cer['distance'] / res_cer['length']))\n",
        "print('WER = {:.2f}%'.format(100. * res_wer['distance'] / res_wer['length']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y WILY O T OE ME R THING MY FES\n",
            "CER = 59.32%\n",
            "WER = 84.62%\n"
          ]
        }
      ]
    }
  ]
}